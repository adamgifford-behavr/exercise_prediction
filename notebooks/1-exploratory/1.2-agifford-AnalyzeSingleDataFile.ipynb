{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2-agifford-AnalyzeSingleDataFile\n",
    "This notebook performs exploratory data analysis on an example datafile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.fftpack import fft, fftshift\n",
    "\n",
    "parq_file = \"../../data/interim/raw/fileID1_subjID3_dataID0.parquet\"\n",
    "df = pd.read_parquet(parq_file, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_single_annot_frame(df, shift):\n",
    "    annot_df = df[df.label != df.label.shift(shift)]\n",
    "    annot_df = annot_df.dropna(subset=\"label\").reset_index()\n",
    "    return annot_df\n",
    "\n",
    "def make_annot_dataframe(df, t_start=None, t_end=None):\n",
    "    t_start = t_start or df.time.min()\n",
    "    t_end = t_end or df.time.max()\n",
    "    \n",
    "    df = df[(df.time >= t_start) & (df.time <= t_end)].copy()\n",
    "    \n",
    "    (act_starts_df, act_ends_df) = (\n",
    "        _make_single_annot_frame(df, shift) for shift in [1, -1]\n",
    "    )\n",
    "    return act_starts_df, act_ends_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure I'll need the starts & ends df, but probably should remove the rows with no \n",
    "# activity labels\n",
    "activity_starts_df, activity_ends_df = make_annot_dataframe(df)\n",
    "df_dropna =  df.dropna(subset=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df_dropna.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropna.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropna.label_group.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of getting through this project end-to-end, I will not spend too much time on building a very sophisticated model. As such, I will use the column `label_group` as my desired prediction column.\n",
    "\n",
    "Process for each `label_group`:\n",
    "1. Compute FFT with a Hanning window for each instance of the `label_group`\n",
    "2. Average the FFTs across instances\n",
    "3. Identify the major frequencies of the group by setting some arbitrary threshold to identify peaks.\n",
    "4. I will use those frequencies to generate `sin` and `cos` features as inputs to a basic model to predict `label_group`.\n",
    "5. Repeat steps 1-4 for each variable x direction combination (e.g., \"accel_x\", \"accel_y\", etc.)\n",
    "\n",
    "First, let's template out the process of analyzing a single instance of a single `label_group`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_tp_df = pd.concat([activity_starts_df.head(1), activity_ends_df.head(1)], ignore_index=True)\n",
    "df_snip = df_dropna[(df_dropna.time >= act_tp_df.loc[0, \"time\"]) & (df_dropna.time <= act_tp_df.loc[1, \"time\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 50\n",
    "n_fft = df_snip.shape[0]\n",
    "window = signal.hann(n_fft)\n",
    "X_w = fft(window * df_snip.accel_x.values)\n",
    "n_points = 2 * int(np.floor(n_fft / 2))\n",
    "if n_fft % 2:\n",
    "    n_points += 1\n",
    "freq = fs/2 * np.linspace(-1, 1, n_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing strong in \"\\<Initial Activity\\>\" except for 0 Hz..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_w_norm = np.abs(fftshift(X_w))\n",
    "X_w_norm = 20 * np.log10(np.abs(fftshift(X_w / abs(X_w).max())))\n",
    "plt.plot(freq, X_w_norm)\n",
    "plt.title(\"Frequency response first activity\")\n",
    "plt.ylabel(\"Normalized magnitude [dB]\")\n",
    "plt.xlabel(\"F [Hz]\")\n",
    "print(act_tp_df.loc[0, \"label\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_tp_df = pd.concat([activity_starts_df.loc[[4], :], activity_ends_df.loc[[4], :]], ignore_index=True)\n",
    "df_snip = df_dropna[(df_dropna.time >= act_tp_df.loc[0, \"time\"]) & (df_dropna.time <= act_tp_df.loc[1, \"time\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, there seem to be many prevalent peaks in \"Jumping Jacks\" at ~1 Hz and 2.75Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 50\n",
    "n_fft = df_snip.shape[0]\n",
    "window = signal.hann(n_fft)\n",
    "X_w = fft(window * df_snip.accel_x.values)\n",
    "n_points = 2 * int(np.floor(n_fft / 2))\n",
    "if n_fft % 2:\n",
    "    n_points += 1\n",
    "freq = fs/2 * np.linspace(-1, 1, n_points)\n",
    "\n",
    "# X_w_norm = np.abs(fftshift(X_w))\n",
    "X_w_norm = 20 * np.log10(np.abs(fftshift(X_w / abs(X_w).max())))\n",
    "\n",
    "a = np.diff(np.sign(np.diff(X_w_norm))).nonzero()[0] + 1               # local min & max\n",
    "b = (np.diff(np.sign(np.diff(X_w_norm))) > 0).nonzero()[0] + 1         # local min\n",
    "c = (np.diff(np.sign(np.diff(X_w_norm))) < 0).nonzero()[0] + 1         # local max\n",
    "# +1 due to the fact that diff reduces the original index number\n",
    "\n",
    "plt.plot(freq, X_w_norm, color=\"grey\")\n",
    "plt.plot(freq, [-10 for _ in X_w_norm], color=\"orange\")\n",
    "plt.plot(freq[b], X_w_norm[b], \"o\", label=\"min\", color='r')\n",
    "plt.plot(freq[c], X_w_norm[c], \"o\", label=\"max\", color='b')\n",
    "plt.title(\"Frequency response first activity\")\n",
    "plt.ylabel(\"Normalized magnitude [dB]\")\n",
    "plt.xlabel(\"F [Hz]\")\n",
    "plt.xlim([0, 5])\n",
    "print(act_tp_df.loc[0, \"label\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a function that pulls out the max of the peaks that cross the threshold (i.e., just gets the 0.02, 0.95, and 2.73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_fmax_above_thresh(freq, x_w, threshold):\n",
    "    local_max_ix = (np.diff(np.sign(np.diff(x_w))) < 0).nonzero()[0] + 1\n",
    "    x_w_max = x_w[local_max_ix]\n",
    "    freq_max = freq[local_max_ix]\n",
    "\n",
    "    return freq_max[np.where((x_w_max>threshold) & (freq_max>0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fmax_above_thresh(freq, X_w_norm, -10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to cycle through all of the activities, and extract the peak frequencies above a particular threshold. What I want to find is an \"ideal\" threshold such that I'm only picking out 2 peak frequencies (3 including 0 Hz) for the majority of activities. This will be the threshold I work with for the rest of the project to extract features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normed_spectrum():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [-5, -10, -15, -20]\n",
    "for r_ix in range(activity_starts_df.shape[0]):\n",
    "    act_tp_df = pd.concat([activity_starts_df.loc[[r_ix], :], activity_ends_df.loc[[r_ix], :]], ignore_index=True)\n",
    "    df_snip = df_dropna[(df_dropna.time >= act_tp_df.loc[0, \"time\"]) & (df_dropna.time <= act_tp_df.loc[1, \"time\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('exercise_prediction')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0bc9e17ecfe5fe569855cd568414bc1d32da1f1775abbcdcf2e86e1b237526b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
