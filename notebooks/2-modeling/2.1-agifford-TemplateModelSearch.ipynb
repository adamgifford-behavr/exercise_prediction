{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1-agifford-TemplateModelSearch\n",
    "This notebook tests and templates the code necessary to build a model to predict `label_group` given frequency features of the various measurement data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_STORE_URI = os.getenv(\"FEATURE_STORE_URI\", \"localhost:5432\")\n",
    "FEATURE_STORE_PW = os.getenv(\"FEATURE_STORE_PW\")\n",
    "FEATURIZE_ID = os.getenv(\"FEATURIZE_ID\")\n",
    "\n",
    "MLFLOW_DB_URI = os.getenv(\"MLFLOW_DB_URI\", \"localhost:5000\")\n",
    "MLFLOW_DB_PW = os.getenv(\"MLFLOW_DB_PW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(f\"http://{MLFLOW_DB_URI}\")\n",
    "client = MlflowClient(f\"http://{MLFLOW_DB_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a sample of the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_URI = f\"postgresql+psycopg2://postgres:{FEATURE_STORE_PW}@{FEATURE_STORE_URI}/feature_store\"\n",
    "engine = sa.create_engine(\n",
    "    DATABASE_URI, \n",
    "    executemany_mode='values',\n",
    "    executemany_values_page_size=10000, \n",
    "    executemany_batch_page_size=500\n",
    ")\n",
    "\n",
    "metadata = sa.schema.MetaData(bind=engine)\n",
    "table = sa.Table(\"naive_frequency_features\", metadata, autoload=True)\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "with Session() as session:\n",
    "    results = (\n",
    "        session\n",
    "        .query(table)\n",
    "        .filter(\n",
    "            sa.and_(\n",
    "                table.c.featurize_id==FEATURIZE_ID,\n",
    "                table.c.dataset_group==\"train\"\n",
    "            )\n",
    "        )\n",
    "        .limit(800)\n",
    "    )\n",
    "\n",
    "\n",
    "train_debug_df = pd.read_sql(\n",
    "    results.statement,\n",
    "    con=engine,\n",
    "    parse_dates=[\"added_datetime\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as session:\n",
    "    results = (\n",
    "        session\n",
    "        .query(table)\n",
    "        .filter(\n",
    "            sa.and_(\n",
    "                table.c.featurize_id==FEATURIZE_ID,\n",
    "                table.c.dataset_group==\"validation\"\n",
    "            )\n",
    "        )\n",
    "        .limit(200)\n",
    "    )\n",
    "\n",
    "\n",
    "val_debug_df = pd.read_sql(\n",
    "    results.statement,\n",
    "    con=engine,\n",
    "    parse_dates=[\"added_datetime\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need this function to manually convert all-string parameters logged in mlflow to true data types for sklearn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_params(params):\n",
    "    converted_params = {}\n",
    "\n",
    "    for key, val in params.items():\n",
    "        # any parameters that specify the files used in the dataset, ignore for model\n",
    "        # purposes\n",
    "        if \"file\" in key:\n",
    "            continue\n",
    "        \n",
    "        # first, check for special types\n",
    "        if val == \"None\":\n",
    "            converted_params[key] = None\n",
    "        if val == \"True\" or val == \"False\":\n",
    "            converted_params[key] = bool(val)\n",
    "        \n",
    "        # next, test for float or int\n",
    "        # since int is more restrictive, place last. that way if int works, it overwrites\n",
    "        # float, else it will fail on int and keep float. and will fail if val is string\n",
    "        try:\n",
    "            converted_params[key] = float(val)\n",
    "            converted_params[key] = int(val)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        # # followed by float (fails on string or special)\n",
    "        # try:\n",
    "            \n",
    "        # except ValueError:\n",
    "        #     pass\n",
    "\n",
    "        # finally, if key not in converted params, val must be string, so leave as is\n",
    "        if key not in converted_params.keys():\n",
    "            converted_params[key] = val\n",
    "\n",
    "    return converted_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the data for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"exercise_prediction_debug_2\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "experiment_id = int(dict(mlflow.get_experiment_by_name(experiment_name))[\"experiment_id\"])\n",
    "X_train = train_debug_df.drop(columns=[\n",
    "    'naive_frequency_features_id', \n",
    "    'featurize_id', \n",
    "    'file', \n",
    "    'dataset_group',\n",
    "    'added_datetime', \n",
    "    'window_size', \n",
    "    't_index', \n",
    "    'label', \n",
    "    'label_group'\n",
    "])\n",
    "# not sure what the issue is, but sklearn was throwing a future warning about the \n",
    "# feature names not all being strings, this fixes the issue...\n",
    "X_train.columns = [str(column) for column in X_train.columns]\n",
    "y_train = train_debug_df[\"label_group\"]\n",
    "\n",
    "X_val = val_debug_df.drop(columns=[\n",
    "    'naive_frequency_features_id', \n",
    "    'featurize_id', \n",
    "    'file', \n",
    "    'dataset_group',\n",
    "    'added_datetime', \n",
    "    'window_size', \n",
    "    't_index', \n",
    "    'label', \n",
    "    'label_group'\n",
    "])\n",
    "X_val.columns = [str(column) for column in X_val.columns]\n",
    "y_val = val_debug_df[\"label_group\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_debug_df.file.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, here is a code snippet for a simple run of a series of classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "\n",
    "for model_class in (RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier):\n",
    "    with mlflow.start_run(run_name=\"basic-default-fits\"):\n",
    "        mlflow.set_tag(\"developer\", \"adam gifford\")\n",
    "        mlflow.set_tag(\"model\", model_class.__name__)\n",
    "        mlflow.log_params({\n",
    "            f\"file{n}\": file for n, file in enumerate(train_debug_df.file.unique())\n",
    "        })\n",
    "\n",
    "        mlmodel = model_class(random_state=42)\n",
    "        mlmodel.fit(X_train, y_train)\n",
    "\n",
    "        acc = mlmodel.score(X_val, y_val)\n",
    "        mlflow.log_metric(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results of the runs, with GradientBoostingClassifier the clear winner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment_id,\n",
    "    filter_string=\"\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.accuracy DESC\"],\n",
    ")\n",
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, model: {run.data.tags['model']}, accuracy: {run.data.metrics['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try `GradientBoostingClassifier` with a cross-validated grid search to try to improve the fit results. Here is a code snippet for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(random_state=42, n_iter_no_change=50, tol=1e-3)\n",
    "parameters = {\n",
    "    'learning_rate': [0.01, 0.1, 0.25], \n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'subsample': [0.8, 0.9, 1],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    # 'min_weight_fraction_leaf': [0, 0.25, 0.5],\n",
    "    # 'min_impurity_decrease': [0, 0.01, 0.1],\n",
    "    # 'max_features': ('sqrt', 'log2', None),\n",
    "    # 'max_leaf_nodes': [None, 5, 10],\n",
    "    # 'ccp_alpha': [0, 0.1, 1]\n",
    "}\n",
    "clf = GridSearchCV(gbc, parameters, n_jobs=10)\n",
    "\n",
    "with mlflow.start_run(run_name=\"basic-gridshearch-fit\"):\n",
    "    mlflow.set_tag(\"developer\", \"adam gifford\")\n",
    "    mlflow.set_tag(\"model\", gbc.__class__.__name__)\n",
    "    mlflow.log_params({\n",
    "        f\"file{n}\": file for n, file in enumerate(train_debug_df.file.unique())\n",
    "    })\n",
    "    clf.fit(X_train, y_train)\n",
    "    acc = clf.score(X_val, y_val)\n",
    "    mlflow.log_metric(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `GridSearchCV` took 82 minutes to complete on only 800 rows of data. Will need to be smarter about fitting on the whole dataset if using `GridSearchCV`. Also, the run_name and other manual tags and params options for mlflow run do not seem to work for the resulting best 5 models logged with grid search, only the parent run with the best model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment_id,\n",
    "    filter_string=\"tags.`mlflow.parentRunId` = '05b06f98c9d34145a78f2bd57cc09e6d'\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.accuracy DESC\"],\n",
    ")\n",
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually update the 5 best runs with the desired params, tags and metrics, and log models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.sklearn.autolog(disable=True)\n",
    "for run in runs:\n",
    "    run_id = run.info.run_id\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        mlflow.set_tag(\"developer\", \"adam gifford\")\n",
    "        mlflow.set_tag(\"model\", \"GradientBoostingClassifier\")\n",
    "        mlflow.log_params({\n",
    "            f\"file{n}\": file for n, file in enumerate(train_debug_df.file.unique())\n",
    "        })\n",
    "        params = convert_string_params(run.data.params)\n",
    "        clf = GradientBoostingClassifier(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(clf, artifact_path=\"artifacts\")\n",
    "\n",
    "        acc = clf.score(X_val, y_val)\n",
    "        mlflow.log_metric(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we try using HyperOpt to improve the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    with mlflow.start_run(run_name=\"basic-hyperopt-fit-child\", nested=True):\n",
    "        mlflow.set_tag(\"developer\", \"adam gifford\")\n",
    "        mlflow.set_tag(\"model\", \"GradientBoostingClassifier\")\n",
    "        params.update({\n",
    "            \"random_state\": 42, \n",
    "            \"n_iter_no_change\": 50, \n",
    "            \"tol\": 1e-3, \n",
    "        })\n",
    "        clf = GradientBoostingClassifier(**params)\n",
    "        params.update({\n",
    "            f\"file{n}\": file for n, file in enumerate(train_debug_df.file.unique())\n",
    "        })\n",
    "        mlflow.log_params(params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_val, y_val)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        del clf\n",
    "        gc.collect()\n",
    "\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 10, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 1000, 100)),\n",
    "    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "    'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 6, 1)),\n",
    "    'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 5, 1)),\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=\"basic-hyperopt-fit\"):\n",
    "    best_result = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=20,\n",
    "        trials=Trials()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperopt is a LOT faster, and it achieved a slightly better accuracy, so I will go with this on the full dataset. Below I'm performing the same manual updates to the runs to log tags, params, metrics, and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment_id,\n",
    "    filter_string=\"tags.`mlflow.parentRunId` = '543846fbd0df448a946e0a5b74aa01a1'\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.accuracy DESC\"],\n",
    ")\n",
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    run_id = run.info.run_id\n",
    "    with mlflow.start_run(run_id=run_id):\n",
    "        mlflow.set_tag(\"developer\", \"adam gifford\")\n",
    "        mlflow.set_tag(\"model\", \"GradientBoostingClassifier\")\n",
    "        mlflow.log_params({\n",
    "            f\"file{n}\": file for n, file in enumerate(train_debug_df.file.unique())\n",
    "        })\n",
    "        params = convert_string_params(run.data.params)\n",
    "        clf = GradientBoostingClassifier(**params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(clf, artifact_path=\"artifacts\")\n",
    "\n",
    "        acc = clf.score(X_val, y_val)\n",
    "        mlflow.log_metric(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I will template out code to register models, and transition models between stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking just the top 3 and then reversing the order, because I will model comparing newer \n",
    "# more accurate models with previous versions and transitioning\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment_id,\n",
    "    filter_string=\"\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=3,\n",
    "    order_by=[\"metrics.accuracy DESC\"],\n",
    ")\n",
    "runs = [run for run in runs]\n",
    "runs = [runs[-2], runs[-1], runs[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take \"first\" model and register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = experiment_name\n",
    "first_model = runs[0]\n",
    "run_id = first_model.info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "mlflow.register_model(model_uri=model_uri, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transition registered model to staging, then to production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_model_and_log(model_version, new_stage, archive_existing_versions=False):\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_name,\n",
    "        version=model_version,\n",
    "        stage=new_stage,\n",
    "        archive_existing_versions=archive_existing_versions\n",
    "    )\n",
    "    date = datetime.today().date()\n",
    "    client.update_model_version(\n",
    "        name=model_name,\n",
    "        version=model_version,\n",
    "        description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 1\n",
    "new_stages = [\"Staging\", \"Production\"]\n",
    "for stage in new_stages:\n",
    "    transition_model_and_log(model_version, stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_versions = client.get_latest_versions(name=model_name, stages=[\"Production\"])\n",
    "latest_model_run = client.get_run(run_id=latest_versions[0].run_id)\n",
    "previous_best_acc = latest_model_run.data.metrics[\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_runs = runs[1:]\n",
    "for run in new_runs:\n",
    "    run_id = run.info.run_id\n",
    "    new_acc = run.data.metrics[\"accuracy\"]\n",
    "\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "    \n",
    "    latest_versions = client.get_latest_versions(name=model_name)\n",
    "    current_version = latest_versions[-1].version\n",
    "    transition_model_and_log(current_version, \"Staging\", archive_existing_versions=False)\n",
    "\n",
    "    if new_acc > previous_best_acc:\n",
    "        transition_model_and_log(current_version, \"Production\", archive_existing_versions=True)\n",
    "        previous_best_acc = new_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('exercise_prediction')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0bc9e17ecfe5fe569855cd568414bc1d32da1f1775abbcdcf2e86e1b237526b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
