{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1-agifford-TestLoadMatFileAndVerify\n",
    "This notebook is used to test loading in the data from the .mat file, understanding the organization of the data structure, verifying some properties of the data, and templating a method to convert the data from this confusing format to a simpler dataframe format saved as PARQUET files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi file is best for the \"when are you exercising\" problem (segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matfile = \"../../data/raw/exercise_data.50.0000_multionly.mat\"\n",
    "mat_contents = scipy.io.loadmat(matfile, squeeze_me=True, struct_as_record=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data exists in `subject_data`<br>\n",
    "Exercise labels and label groups exist in `exerciseConstants`<br>\n",
    "Sample rate for all data appears to be `Fs=50` Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'subject_data', 'exerciseConstants', 'Fs'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_contents.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within `exerciseConstants`, there are 2 fields<br>\n",
    "`activities` is thr raw list of all possible labels<br>\n",
    "`usefulActivityGroupings` is a 13x2 ndarray in the form of `[group_name, [array of labels for this group]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['<Initial Activity>', 'Arm Band Adjustment', 'Arm straight up',\n",
       "        'Band Pull-Down Row', 'Bicep Curl', 'Biceps Curl (band)',\n",
       "        'Box Jump (on bench)', 'Burpee', 'Butterfly Sit-up',\n",
       "        'Chest Press (rack)'], dtype=object),\n",
       " array(['Junk',\n",
       "        array(['Arm Band Adjustment', 'Arm straight up', 'Unlisted Exercise',\n",
       "               'Note', 'Tap IMU Device', 'Tap Left Device', 'Tap Right Device',\n",
       "               '<Initial Activity>', 'Activities', 'Invalid'], dtype=object)   ],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise_constants = mat_contents[\"exerciseConstants\"]\n",
    "exercise_constants.activities[:10], exercise_constants.usefulActivityGroupings[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 94 subject's worth of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many subjects are there?\n",
    "mat_contents['subject_data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Within each subject, there are one or more arrays of `scipy.io.matlab._mio5_params.mat_struct`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<scipy.io.matlab._mio5_params.mat_struct object at 0x00000270069D4220>\n",
      " <scipy.io.matlab._mio5_params.mat_struct object at 0x00000270069D71F0>\n",
      " <scipy.io.matlab._mio5_params.mat_struct object at 0x0000027006966200>\n",
      " <scipy.io.matlab._mio5_params.mat_struct object at 0x0000027006991270>\n",
      " <scipy.io.matlab._mio5_params.mat_struct object at 0x00000270067D54E0>]\n",
      "<scipy.io.matlab._mio5_params.mat_struct object at 0x00000270068F3400>\n",
      "<scipy.io.matlab._mio5_params.mat_struct object at 0x00000270068072E0>\n",
      "<scipy.io.matlab._mio5_params.mat_struct object at 0x00000270069EAB00>\n",
      "<scipy.io.matlab._mio5_params.mat_struct object at 0x00000270057219F0>\n",
      "<scipy.io.matlab._mio5_params.mat_struct object at 0x0000027017D9EEC0>\n",
      "[<scipy.io.matlab._mio5_params.mat_struct object at 0x0000027005721BD0>\n",
      " <scipy.io.matlab._mio5_params.mat_struct object at 0x00000270067DCBE0>\n",
      " <scipy.io.matlab._mio5_params.mat_struct object at 0x00000270067DD3C0>\n",
      " <scipy.io.matlab._mio5_params.mat_struct object at 0x00000270067DDAE0>]\n"
     ]
    }
   ],
   "source": [
    "# what's in each subjects data structure?\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if ix>6:\n",
    "        continue\n",
    "    print(subj_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like all `scipy.io.matlab._mio5_params.mat_struct` data has identical fieldnames, so we only need to gather the field names once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field names for all mat_structs are the same\n"
     ]
    }
   ],
   "source": [
    "# are field names identical across subjects and arrays?\n",
    "def check_for_identical_fieldnames(first_fieldnames, next_fieldnames, level=\"assert\", msg=1, ix=None, jx=0):\n",
    "    if msg == 1:\n",
    "        msg = (\n",
    "            f\"Not all fieldnames match between subject_index {ix} and first subject. \"\n",
    "            f\"First inconsistent index is {jx}\"\n",
    "        )\n",
    "    elif msg == 2:\n",
    "        msg = (\n",
    "            f\"Not all activities data match for subject_index {ix}. First inconsistent\"\n",
    "            f\" index is {jx}\"\n",
    "        )\n",
    "    elif msg == 3:\n",
    "        msg = (\n",
    "            f\"MasterFileToken does not match MasterToken for subject_index {ix}. First \"\n",
    "            f\"inconsistent index is {jx}\"\n",
    "        )\n",
    "    elif msg == 4:\n",
    "        msg = (\n",
    "            f\"MasterFileTokens & MasterTokens for subject_index {ix} do not match across \"\n",
    "            f\"arrays. First inconsistent index is {jx}\"\n",
    "        )\n",
    "    elif msg == 5:\n",
    "        msg = (\n",
    "            f\"Not all instanceIndex's match for subject_index {ix}. First inconsistent \"\n",
    "            f\"index is {jx}\"\n",
    "        )\n",
    "\n",
    "    check = all([f==n for f, n in zip(first_fieldnames, next_fieldnames)])\n",
    "    if level == \"assert\":\n",
    "        assert check, msg\n",
    "    else:  # level == \"warn\":\n",
    "        if not check:\n",
    "            warn(msg)\n",
    "    return\n",
    "\n",
    "first_fieldnames = mat_contents['subject_data'][0][0]._fieldnames\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        for jx, data in enumerate(subj_data):\n",
    "            next_fieldnames = data._fieldnames\n",
    "            check_for_identical_fieldnames(first_fieldnames, next_fieldnames, ix=ix, jx=jx)\n",
    "    else:\n",
    "        next_fieldnames = subj_data._fieldnames\n",
    "        check_for_identical_fieldnames(first_fieldnames, next_fieldnames)\n",
    "\n",
    "print(\"Field names for all mat_structs are the same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each array reflects a separate workout instance, with a varying number of activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 0\n",
      "File 1; Subject 3; Activity 1: Activities; Instance 1; Master File Token: rightArm, Master Token rightArm; Data shape: (127959, 4); Time_Start: 0.0, Time_End: 2559.154\n",
      "N_Activities=33\n",
      "\n",
      "Array 1\n",
      "File 51; Subject 3; Activity 1: Activities; Instance 1; Master File Token: rightArm, Master Token rightArm; Data shape: (90326, 4); Time_Start: 0.0, Time_End: 1806.496\n",
      "N_Activities=45\n",
      "\n",
      "Array 2\n",
      "File 87; Subject 3; Activity 1: Activities; Instance 1; Master File Token: rightArm, Master Token rightArm; Data shape: (107313, 4); Time_Start: 0.0, Time_End: 2146.237\n",
      "N_Activities=41\n",
      "\n",
      "Array 3\n",
      "File 110; Subject 3; Activity 1: Activities; Instance 1; Master File Token: rightArm, Master Token rightArm; Data shape: (119799, 4); Time_Start: 0.0, Time_End: 2395.944\n",
      "N_Activities=37\n",
      "\n",
      "Array 4\n",
      "File 146; Subject 3; Activity 1: Activities; Instance 1; Master File Token: rightArm, Master Token rightArm; Data shape: (133644, 4); Time_Start: 0.0, Time_End: 2672.843\n",
      "N_Activities=34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the difference between subjects with an array of mat_structs vs. a subject \n",
    "# with only one mat_struct? Subject 0 has an array of mat_structs, let's see what's \n",
    "# inside them...\n",
    "for ix, struct in enumerate(mat_contents[\"subject_data\"][0]):\n",
    "    f_ix, subject_id = struct.fileIndex, struct.subjectID\n",
    "    a_ix, activity_name = struct.activityIndex, struct.activityName\n",
    "    i_ix, shape = struct.instanceIndex, struct.data.accelDataMatrix.shape\n",
    "    mf_tok, m_tok = struct.masterFileToken, struct.masterToken\n",
    "    t_start, t_end = (\n",
    "        struct.data.accelDataMatrix[0,0], \n",
    "        struct.data.accelDataMatrix[-1,0]\n",
    "    )\n",
    "    n_activities = struct.activityStartMatrix.shape[0]\n",
    "    print(f\"Array {ix}\")\n",
    "    print((\n",
    "        f\"File {f_ix}; Subject {subject_id}; Activity {a_ix}: {activity_name}; Instance \"\n",
    "        f\"{i_ix}; Master File Token: {mf_tok}, Master Token {m_tok}; Data shape: {shape}; \"\n",
    "        f\"Time_Start: {t_start}, Time_End: {t_end}\"\n",
    "    ))\n",
    "    print(f\"N_Activities={n_activities}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For subjects with more than one data array, it appears that `activityIndex` and `activityName` are all identical, so we only need to look at these fields once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activities data for all subjects with arrays of data are the same\n"
     ]
    }
   ],
   "source": [
    "# for all subject data, let's see if activityIndex, activityName are all the same for each array of data\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        firsts = subj_data[0].activityIndex, subj_data[0].activityName\n",
    "        for jx, data in enumerate(subj_data):\n",
    "            nexts = data.activityIndex, data.activityName\n",
    "            check_for_identical_fieldnames(firsts, nexts, msg=2, ix=ix, jx=jx)\n",
    "    else:\n",
    "        # if there is only 1 data struct, there's no need to compare\n",
    "        continue\n",
    "print(\"Activities data for all subjects with arrays of data are the same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, all `activityIndex`s and `activityName`s are identical across all subjects and arrays. Considering how generic these are, they can be ignored entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1}\n",
      "{'Activities'}\n"
     ]
    }
   ],
   "source": [
    "# what are all of the possible `activityIndex`s and `activityName`s?\n",
    "all_activity_ixs = []\n",
    "all_activity_names = []\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        a_ix, activity_name = struct.activityIndex, struct.activityName\n",
    "    else:\n",
    "        a_ix, activity_name = subj_data.activityIndex, subj_data.activityName\n",
    "\n",
    "    all_activity_ixs.append(a_ix)\n",
    "    all_activity_names.append(activity_name)\n",
    "\n",
    "print(set(all_activity_ixs))\n",
    "print(set(all_activity_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that `masterFileToken` and `masterToken` reflect the same values within a subject, regardless of how many data arrays (i.e., number of separate workout instances) a subject completed. So for each subject, we only need to look at the first `masterToken`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasterFileTokens and masterTokens match for all arrays within a subject\n"
     ]
    }
   ],
   "source": [
    "# now let's see if masterFileToken == masterToken within each array of data for a subject (assert)\n",
    "# and see if firsts == nexts across arrays for a subject (just identify differences, don't assert)\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        firsts = subj_data[0].masterFileToken, subj_data[0].masterToken\n",
    "        for jx, data in enumerate(subj_data):\n",
    "            nexts = data.masterFileToken, data.masterToken\n",
    "            f_tok, n_tok = nexts\n",
    "            check_for_identical_fieldnames([f_tok], [n_tok], msg=3, ix=ix, jx=jx)\n",
    "            check_for_identical_fieldnames(firsts, nexts, level=\"warn\", msg=4, ix=ix, jx=jx)\n",
    "    else:\n",
    "        nexts = subj_data.masterFileToken, subj_data.masterToken\n",
    "        f_tok, n_tok = nexts\n",
    "        check_for_identical_fieldnames([f_tok], [n_tok], msg=3, ix=ix, jx=jx)\n",
    "print(\"MasterFileTokens and masterTokens match for all arrays within a subject\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, it appears that all data comes from subjects' right arms, so we can ignore this field entirely as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rightArm'}\n"
     ]
    }
   ],
   "source": [
    "# what are all of the possible master_tokens?\n",
    "all_master_tokens = []\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        master_token = subj_data[0].masterToken\n",
    "    else:\n",
    "        master_token = subj_data.masterToken\n",
    "    all_master_tokens.append(master_token)\n",
    "\n",
    "print(set(all_master_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for subjects with an array of data, all `instanceIndex`s are identical, so we can ignore these as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance index data for all subjects with arrays of data are the same\n"
     ]
    }
   ],
   "source": [
    "# what about `instance`?\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        first_ix = [subj_data[0].instanceIndex]\n",
    "        for jx, data in enumerate(subj_data):\n",
    "            next_ix = [data.instanceIndex]\n",
    "            check_for_identical_fieldnames(first_ix, next_ix, msg=5, ix=ix, jx=jx)\n",
    "    else:\n",
    "        # if there is only 1 data struct, there's no need to compare\n",
    "        continue\n",
    "print(\"Instance index data for all subjects with arrays of data are the same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet below runs through one array from one subject's data and aligns the activity labels with the time axis of the accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how can we build a dataframe that labels activity appropriately?\n",
    "# let's start with one array from one subject's data\n",
    "subj0_data = mat_contents['subject_data'][0]\n",
    "time = subj0_data[0].data.accelDataMatrix[:,0]\n",
    "max_t = time[-1]\n",
    "activity_array = np.empty_like(time, dtype=\"object\")\n",
    "for activity in subj0_data[0].activityStartMatrix:\n",
    "    activity_name = activity[0]\n",
    "    t_s, t_e = activity[1:3]\n",
    "\n",
    "    # enforce that times fit between start and end times in data matrix\n",
    "    t_s = 0 if t_s < 0 else t_s\n",
    "    t_e = max_t if t_e > max_t else t_e\n",
    "    act_ix = (time >= t_s) & (time <= t_e)\n",
    "    activity_array[act_ix] = activity_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just check that the time axis for the accelerometer is the same as that for the gyroscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time axes match\n"
     ]
    }
   ],
   "source": [
    "time_g = subj0_data[0].data.gyroDataMatrix[:,0]\n",
    "assert all(t==t_g for t, t_g in zip(time, time_g)), \"Time axes don't match\"\n",
    "print(\"Time axes match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to put subject data into a dataframe format and then save it as a parquet or csv file for further exploration. Files will reflect one data array for one subject, and file names will be of the form: `fileID_subjID_dataID` where `fileID` is the value in the `fileIndex` field, `subjID` is the value in the `subjectID` field, and `dataID` is the data array index representing the exercise run (0 by default for subjects with only one data structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to put subject data into a dataframe\n",
    "# identifiers i'll need are:\n",
    "# file number\n",
    "# subject number\n",
    "# data array index (0 by default if only 1, otherwise index of struct in subj_data)\n",
    "# time\n",
    "# accel_x\n",
    "# accel_y\n",
    "# accel_z\n",
    "# gyro_x\n",
    "# gyro_y\n",
    "# gro_z\n",
    "# activity_label\n",
    "df_s0_d0 = pd.DataFrame()\n",
    "data_ix = 0\n",
    "time = subj0_data[data_ix].data.accelDataMatrix[:,0]\n",
    "f_ix = subj0_data[data_ix].fileIndex\n",
    "s_ix = subj0_data[data_ix].subjectID\n",
    "\n",
    "df_s0_d0[\"time\"] = time\n",
    "df_s0_d0[\"file_id\"] = f_ix\n",
    "df_s0_d0[\"subject_id\"] = s_ix\n",
    "df_s0_d0[\"data_id\"] = data_ix\n",
    "\n",
    "df_s0_d0[\"accel_x\"] = subj0_data[data_ix].data.accelDataMatrix[:,1]\n",
    "df_s0_d0[\"accel_y\"] = subj0_data[data_ix].data.accelDataMatrix[:,2]\n",
    "df_s0_d0[\"accel_z\"] = subj0_data[data_ix].data.accelDataMatrix[:,3]\n",
    "\n",
    "df_s0_d0[\"gyro_x\"] = subj0_data[data_ix].data.gyroDataMatrix[:,1]\n",
    "df_s0_d0[\"gyro_y\"] = subj0_data[data_ix].data.gyroDataMatrix[:,2]\n",
    "df_s0_d0[\"gyro_z\"] = subj0_data[data_ix].data.gyroDataMatrix[:,3]\n",
    "\n",
    "max_t = time[-1]\n",
    "activity_array = np.empty_like(time, dtype=\"object\")\n",
    "for activity in subj0_data[data_ix].activityStartMatrix:\n",
    "    activity_name = activity[0]\n",
    "    t_s, t_e = activity[1:3]\n",
    "\n",
    "    # enforce that times fit between start and end times in data matrix\n",
    "    t_s = 0 if t_s < 0 else t_s\n",
    "    t_e = max_t if t_e > max_t else t_e\n",
    "    act_ix = (time >= t_s) & (time <= t_e)\n",
    "    activity_array[act_ix] = activity_name\n",
    "\n",
    "df_s0_d0[\"label\"] = activity_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "output_file =  f\"../../data/interim/raw/fileID{f_ix}_subjID{s_ix}_dataID{data_ix}.parquet\"\n",
    "df_s0_d0.to_parquet(\n",
    "    output_file,\n",
    "    engine='fastparquet',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_single_parquet_file(subj_data, data_ix):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    time = subj_data.data.accelDataMatrix[:,0]\n",
    "    file_ix = subj_data.fileIndex\n",
    "    subj_ix = subj_data.subjectID\n",
    "\n",
    "    df[\"time\"] = time\n",
    "    df[\"file_id\"] = file_ix\n",
    "    df[\"subject_id\"] = subj_ix\n",
    "    df[\"data_id\"] = data_ix\n",
    "\n",
    "    df[\"accel_x\"] = subj_data.data.accelDataMatrix[:,1]\n",
    "    df[\"accel_y\"] = subj_data.data.accelDataMatrix[:,2]\n",
    "    df[\"accel_z\"] = subj_data.data.accelDataMatrix[:,3]\n",
    "\n",
    "    df[\"gyro_x\"] = subj_data.data.gyroDataMatrix[:,1]\n",
    "    df[\"gyro_y\"] = subj_data.data.gyroDataMatrix[:,2]\n",
    "    df[\"gyro_z\"] = subj_data.data.gyroDataMatrix[:,3]\n",
    "\n",
    "    max_t = time[-1]\n",
    "    activity_array = np.empty_like(time, dtype=\"object\")\n",
    "    for activity in subj_data.activityStartMatrix:\n",
    "        activity_name = activity[0]\n",
    "        t_s, t_e = activity[1:3]\n",
    "\n",
    "        # enforce that times fit between start and end times in data matrix\n",
    "        t_s = 0 if t_s < 0 else t_s\n",
    "        t_e = max_t if t_e > max_t else t_e\n",
    "\n",
    "        act_ix = (time >= t_s) & (time <= t_e)\n",
    "        activity_array[act_ix] = activity_name\n",
    "\n",
    "    df[\"label\"] = activity_array\n",
    "    \n",
    "    # save the data\n",
    "    output_file =  (\n",
    "        f\"../../data/interim/raw/fileID{file_ix}_subjID{subj_ix}_dataID{data_ix}.parquet\"\n",
    "    )\n",
    "    df.to_parquet(output_file, engine='fastparquet')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\r"
     ]
    }
   ],
   "source": [
    "# now, build out the code to re-write the data by fileID, subjID, and dataID\n",
    "for ix, subj_data in enumerate(mat_contents[\"subject_data\"]):\n",
    "    print(ix, end=\"\\r\")\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        for d_ix, subj_data_x in enumerate(subj_data):\n",
    "            write_single_parquet_file(subj_data_x, d_ix)\n",
    "    else:\n",
    "        write_single_parquet_file(subj_data, data_ix=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyarrow breaks the kernel and I don't know why, but fastparquet works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\adamgifford_behavr.DESKTOP-PQU0D8M\\Documents\\DataScience\\PersonalProjects\\exercise_prediction\\notebooks\\0-setup\\0.1-agifford-TestLoadMatFileAndVerify.ipynb Cell 37\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/adamgifford_behavr.DESKTOP-PQU0D8M/Documents/DataScience/PersonalProjects/exercise_prediction/notebooks/0-setup/0.1-agifford-TestLoadMatFileAndVerify.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file =  f\"../../data/interim/raw/fileID{f_ix}_subjID{s_ix}_dataID{data_ix}-pa.parquet\"\n",
    "df_s0_d0.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('exercise_prediction')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0bc9e17ecfe5fe569855cd568414bc1d32da1f1775abbcdcf2e86e1b237526b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
