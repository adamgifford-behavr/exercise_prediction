{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi file is best for the \"when are you exercising\" problem (segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matfile = \"../../data/raw/exercise_data.50.0000_multionly.mat\"\n",
    "mat_contents = scipy.io.loadmat(matfile, squeeze_me=True, struct_as_record=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data exists in `subject_data`<br>\n",
    "Exercise labels and label groups exist in `exerciseConstants`<br>\n",
    "Sample rate for all data appears to be `Fs=50` Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within `exerciseConstants`, there are 2 fields<br>\n",
    "`activities` is thr raw list of all possible labels<br>\n",
    "`usefulActivityGroupings` is a 13x2 ndarray in the form of `[group_name, [array of labels for this group]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_constants = mat_contents[\"exerciseConstants\"]\n",
    "exercise_constants.activities[:10], exercise_constants.usefulActivityGroupings[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 94 subject's worth of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many subjects are there?\n",
    "mat_contents['subject_data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Within each subject, there are one or more arrays of `scipy.io.matlab._mio5_params.mat_struct`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's in each subjects data structure?\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if ix>6:\n",
    "        continue\n",
    "    print(subj_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like all `scipy.io.matlab._mio5_params.mat_struct` data has identical fieldnames, so we only need to gather the field names once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are field names identical across subjects and arrays?\n",
    "def check_for_identical_fieldnames(first_fieldnames, next_fieldnames, level=\"assert\", msg=1, ix=None, jx=0):\n",
    "    if msg == 1:\n",
    "        msg = (\n",
    "            f\"Not all fieldnames match between subject_index {ix} and first subject. \"\n",
    "            f\"First inconsistent index is {jx}\"\n",
    "        )\n",
    "    elif msg == 2:\n",
    "        msg = (\n",
    "            f\"Not all activities data match for subject_index {ix}. First inconsistent\"\n",
    "            f\" index is {jx}\"\n",
    "        )\n",
    "    elif msg == 3:\n",
    "        msg = (\n",
    "            f\"MasterFileToken does not match MasterToken for subject_index {ix}. First \"\n",
    "            f\"inconsistent index is {jx}\"\n",
    "        )\n",
    "    elif msg == 4:\n",
    "        msg = (\n",
    "            f\"MasterFileTokens & MasterTokens for subject_index {ix} do not match across \"\n",
    "            f\"arrays. First inconsistent index is {jx}\"\n",
    "        )\n",
    "    elif msg == 5:\n",
    "        msg = (\n",
    "            f\"Not all instanceIndex's match for subject_index {ix}. First inconsistent \"\n",
    "            f\"index is {jx}\"\n",
    "        )\n",
    "\n",
    "    check = all([f==n for f, n in zip(first_fieldnames, next_fieldnames)])\n",
    "    if level == \"assert\":\n",
    "        assert check, msg\n",
    "    else:  # level == \"warn\":\n",
    "        if not check:\n",
    "            warn(msg)\n",
    "    return\n",
    "\n",
    "first_fieldnames = mat_contents['subject_data'][0][0]._fieldnames\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        for jx, data in enumerate(subj_data):\n",
    "            next_fieldnames = data._fieldnames\n",
    "            check_for_identical_fieldnames(first_fieldnames, next_fieldnames, ix=ix, jx=jx)\n",
    "    else:\n",
    "        next_fieldnames = subj_data._fieldnames\n",
    "        check_for_identical_fieldnames(first_fieldnames, next_fieldnames)\n",
    "\n",
    "print(\"Field names for all mat_structs are the same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each array reflects a separate workout instance, with a varying number of activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the difference between subjects with an array of mat_structs vs. a subject \n",
    "# with only one mat_struct? Subject 0 has an array of mat_structs, let's see what's \n",
    "# inside them...\n",
    "for ix, struct in enumerate(mat_contents[\"subject_data\"][0]):\n",
    "    f_ix, subject_id = struct.fileIndex, struct.subjectID\n",
    "    a_ix, activity_name = struct.activityIndex, struct.activityName\n",
    "    i_ix, shape = struct.instanceIndex, struct.data.accelDataMatrix.shape\n",
    "    mf_tok, m_tok = struct.masterFileToken, struct.masterToken\n",
    "    t_start, t_end = (\n",
    "        struct.data.accelDataMatrix[0,0], \n",
    "        struct.data.accelDataMatrix[-1,0]\n",
    "    )\n",
    "    n_activities = struct.activityStartMatrix.shape[0]\n",
    "    print(f\"Array {ix}\")\n",
    "    print((\n",
    "        f\"File {f_ix}; Subject {subject_id}; Activity {a_ix}: {activity_name}; Instance \"\n",
    "        f\"{i_ix}; Master File Token: {mf_tok}, Master Token {m_tok}; Data shape: {shape}; \"\n",
    "        f\"Time_Start: {t_start}, Time_End: {t_end}\"\n",
    "    ))\n",
    "    print(f\"N_Activities={n_activities}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For subjects with more than one data array, it appears that `activityIndex` and `activityName` are all identical, so we only need to look at these fields once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all subject data, let's see if activityIndex, activityName are all the same for each array of data\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        firsts = subj_data[0].activityIndex, subj_data[0].activityName\n",
    "        for jx, data in enumerate(subj_data):\n",
    "            nexts = data.activityIndex, data.activityName\n",
    "            check_for_identical_fieldnames(firsts, nexts, msg=2, ix=ix, jx=jx)\n",
    "    else:\n",
    "        # if there is only 1 data struct, there's no need to compare\n",
    "        continue\n",
    "print(\"Activities data for all subjects with arrays of data are the same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, all `activityIndex`s and `activityName`s are identical across all subjects and arrays. Considering how generic these are, they can be ignored entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are all of the possible `activityIndex`s and `activityName`s?\n",
    "all_activity_ixs = []\n",
    "all_activity_names = []\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        a_ix, activity_name = struct.activityIndex, struct.activityName\n",
    "    else:\n",
    "        a_ix, activity_name = subj_data.activityIndex, subj_data.activityName\n",
    "\n",
    "    all_activity_ixs.append(a_ix)\n",
    "    all_activity_names.append(activity_name)\n",
    "\n",
    "print(set(all_activity_ixs))\n",
    "print(set(all_activity_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that `masterFileToken` and `masterToken` reflect the same values within a subject, regardless of how many data arrays (i.e., number of separate workout instances) a subject completed. So for each subject, we only need to look at the first `masterToken`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's see if masterFileToken == masterToken within each array of data for a subject (assert)\n",
    "# and see if firsts == nexts across arrays for a subject (just identify differences, don't assert)\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        firsts = subj_data[0].masterFileToken, subj_data[0].masterToken\n",
    "        for jx, data in enumerate(subj_data):\n",
    "            nexts = data.masterFileToken, data.masterToken\n",
    "            f_tok, n_tok = nexts\n",
    "            check_for_identical_fieldnames([f_tok], [n_tok], msg=3, ix=ix, jx=jx)\n",
    "            check_for_identical_fieldnames(firsts, nexts, level=\"warn\", msg=4, ix=ix, jx=jx)\n",
    "    else:\n",
    "        nexts = subj_data.masterFileToken, subj_data.masterToken\n",
    "        f_tok, n_tok = nexts\n",
    "        check_for_identical_fieldnames([f_tok], [n_tok], msg=3, ix=ix, jx=jx)\n",
    "print(\"MasterFileTokens and masterTokens match for all arrays within a subject\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, it appears that all data comes from subjects' right arms, so we can ignore this field entirely as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are all of the possible master_tokens?\n",
    "all_master_tokens = []\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        master_token = subj_data[0].masterToken\n",
    "    else:\n",
    "        master_token = subj_data.masterToken\n",
    "    all_master_tokens.append(master_token)\n",
    "\n",
    "print(set(all_master_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for subjects with an array of data, all `instanceIndex`s are identical, so we can ignore these as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about `instance`?\n",
    "for ix, subj_data in enumerate(mat_contents['subject_data']):\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        first_ix = [subj_data[0].instanceIndex]\n",
    "        for jx, data in enumerate(subj_data):\n",
    "            next_ix = [data.instanceIndex]\n",
    "            check_for_identical_fieldnames(first_ix, next_ix, msg=5, ix=ix, jx=jx)\n",
    "    else:\n",
    "        # if there is only 1 data struct, there's no need to compare\n",
    "        continue\n",
    "print(\"Instance index data for all subjects with arrays of data are the same\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet below runs through one array from one subject's data and aligns the activity labels with the time axis of the accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how can we build a dataframe that labels activity appropriately?\n",
    "# let's start with one array from one subject's data\n",
    "subj0_data = mat_contents['subject_data'][0]\n",
    "time = subj0_data[0].data.accelDataMatrix[:,0]\n",
    "max_t = time[-1]\n",
    "activity_array = np.empty_like(time, dtype=\"object\")\n",
    "for activity in subj0_data[0].activityStartMatrix:\n",
    "    activity_name = activity[0]\n",
    "    t_s, t_e = activity[1:3]\n",
    "\n",
    "    # enforce that times fit between start and end times in data matrix\n",
    "    t_s = 0 if t_s < 0 else t_s\n",
    "    t_e = max_t if t_e > max_t else t_e\n",
    "    act_ix = (time >= t_s) & (time <= t_e)\n",
    "    activity_array[act_ix] = activity_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just check that the time axis for the accelerometer is the same as that for the gyroscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_g = subj0_data[0].data.gyroDataMatrix[:,0]\n",
    "assert all(t==t_g for t, t_g in zip(time, time_g)), \"Time axes don't match\"\n",
    "print(\"Time axes match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to put subject data into a dataframe format and then save it as a parquet or csv file for further exploration. Files will reflect one data array for one subject, and file names will be of the form: `fileID_subjID_dataID` where `fileID` is the value in the `fileIndex` field, `subjID` is the value in the `subjectID` field, and `dataID` is the data array index representing the exercise run (0 by default for subjects with only one data structure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to put subject data into a dataframe\n",
    "# identifiers i'll need are:\n",
    "# file number\n",
    "# subject number\n",
    "# data array index (0 by default if only 1, otherwise index of struct in subj_data)\n",
    "# time\n",
    "# accel_x\n",
    "# accel_y\n",
    "# accel_z\n",
    "# gyro_x\n",
    "# gyro_y\n",
    "# gro_z\n",
    "# activity_label\n",
    "df_s0_d0 = pd.DataFrame()\n",
    "data_ix = 0\n",
    "time = subj0_data[data_ix].data.accelDataMatrix[:,0]\n",
    "f_ix = subj0_data[data_ix].fileIndex\n",
    "s_ix = subj0_data[data_ix].subjectID\n",
    "\n",
    "df_s0_d0[\"time\"] = time\n",
    "df_s0_d0[\"file_id\"] = f_ix\n",
    "df_s0_d0[\"subject_id\"] = s_ix\n",
    "df_s0_d0[\"data_id\"] = data_ix\n",
    "\n",
    "df_s0_d0[\"accel_x\"] = subj0_data[data_ix].data.accelDataMatrix[:,1]\n",
    "df_s0_d0[\"accel_y\"] = subj0_data[data_ix].data.accelDataMatrix[:,2]\n",
    "df_s0_d0[\"accel_z\"] = subj0_data[data_ix].data.accelDataMatrix[:,3]\n",
    "\n",
    "df_s0_d0[\"gyro_x\"] = subj0_data[data_ix].data.gyroDataMatrix[:,1]\n",
    "df_s0_d0[\"gyro_y\"] = subj0_data[data_ix].data.gyroDataMatrix[:,2]\n",
    "df_s0_d0[\"gyro_z\"] = subj0_data[data_ix].data.gyroDataMatrix[:,3]\n",
    "\n",
    "max_t = time[-1]\n",
    "activity_array = np.empty_like(time, dtype=\"object\")\n",
    "for activity in subj0_data[data_ix].activityStartMatrix:\n",
    "    activity_name = activity[0]\n",
    "    t_s, t_e = activity[1:3]\n",
    "\n",
    "    # enforce that times fit between start and end times in data matrix\n",
    "    t_s = 0 if t_s < 0 else t_s\n",
    "    t_e = max_t if t_e > max_t else t_e\n",
    "    act_ix = (time >= t_s) & (time <= t_e)\n",
    "    activity_array[act_ix] = activity_name\n",
    "\n",
    "df_s0_d0[\"label\"] = activity_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "output_file =  f\"../../data/interim/raw/fileID{f_ix}_subjID{s_ix}_dataID{data_ix}.parquet\"\n",
    "df_s0_d0.to_parquet(\n",
    "    output_file,\n",
    "    engine='fastparquet',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_single_parquet_file(subj_data, data_ix):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    time = subj_data.data.accelDataMatrix[:,0]\n",
    "    file_ix = subj_data.fileIndex\n",
    "    subj_ix = subj_data.subjectID\n",
    "\n",
    "    df[\"time\"] = time\n",
    "    df[\"file_id\"] = file_ix\n",
    "    df[\"subject_id\"] = subj_ix\n",
    "    df[\"data_id\"] = data_ix\n",
    "\n",
    "    df[\"accel_x\"] = subj_data.data.accelDataMatrix[:,1]\n",
    "    df[\"accel_y\"] = subj_data.data.accelDataMatrix[:,2]\n",
    "    df[\"accel_z\"] = subj_data.data.accelDataMatrix[:,3]\n",
    "\n",
    "    df[\"gyro_x\"] = subj_data.data.gyroDataMatrix[:,1]\n",
    "    df[\"gyro_y\"] = subj_data.data.gyroDataMatrix[:,2]\n",
    "    df[\"gyro_z\"] = subj_data.data.gyroDataMatrix[:,3]\n",
    "\n",
    "    max_t = time[-1]\n",
    "    activity_array = np.empty_like(time, dtype=\"object\")\n",
    "    for activity in subj_data.activityStartMatrix:\n",
    "        activity_name = activity[0]\n",
    "        t_s, t_e = activity[1:3]\n",
    "\n",
    "        # enforce that times fit between start and end times in data matrix\n",
    "        t_s = 0 if t_s < 0 else t_s\n",
    "        t_e = max_t if t_e > max_t else t_e\n",
    "\n",
    "        act_ix = (time >= t_s) & (time <= t_e)\n",
    "        activity_array[act_ix] = activity_name\n",
    "\n",
    "    df[\"label\"] = activity_array\n",
    "    \n",
    "    # save the data\n",
    "    output_file =  (\n",
    "        f\"../../data/interim/raw/fileID{file_ix}_subjID{subj_ix}_dataID{data_ix}.parquet\"\n",
    "    )\n",
    "    df.to_parquet(output_file, engine='fastparquet')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, build out the code to re-write the data by fileID, subjID, and dataID\n",
    "for ix, subj_data in enumerate(mat_contents[\"subject_data\"]):\n",
    "    print(ix, end=\"\\r\")\n",
    "    if isinstance(subj_data, np.ndarray):\n",
    "        for d_ix, subj_data_x in enumerate(subj_data):\n",
    "            write_single_parquet_file(subj_data_x, d_ix)\n",
    "    else:\n",
    "        write_single_parquet_file(subj_data, data_ix=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyarrow breaks the kernel and I don't know why, but fastparquet works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file =  f\"../../data/interim/raw/fileID{f_ix}_subjID{s_ix}_dataID{data_ix}-pa.parquet\"\n",
    "df_s0_d0.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('exercise_prediction')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0bc9e17ecfe5fe569855cd568414bc1d32da1f1775abbcdcf2e86e1b237526b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
